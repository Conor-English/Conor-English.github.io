---
title: "Project 1: Predicting Breakout Footballers with Machine Learning"
format:
  html:
    code-fold: true
    code-summary: "Show the code"
    code-tools: true
execute:
  echo: true
  eval: true
---

# ⚽ Overview

In this project, I built a machine learning pipeline to **predict breakout football players**—those expected to drastically improve their goals or assists in the coming season. This was done using real-world player statistics and advanced ML interpretability tools like SHAP.

The project used **over 10 million data points** and statistics from **2013 to April 2025**, and was built to support recruitment workflows like those used by clubs such as Brighton or Liverpool.

# 🛠️ Skills Demonstrated

- Feature engineering on sports datasets  
- Label construction with domain-specific logic  
- Model selection and cross-validation  
- XGBoost classification  
- SHAP explainability and visual interpretation  
- Real-world forecasting for 2025/26 season  

# 📊 Dataset and Features

The dataset came from [Transfermarkt](https://www.transfermarkt.com/) via Kaggle and included:

- Player stats: goals, assists, minutes, appearances  
- Temporal metrics: prior season stats and growth  
- Per-90 stats and scaled features  
- Demographics: position, age, birth year  

Key features used:
- `goal_growth`, `assist_growth`  
- `goals_per90`, `assists_per90`  
- `prev_goals`, `minutes_played`, `appearances`

# 🤖 Model Pipeline

- Model: XGBoost Classifier  
- Training: 80/20 split with 5-fold CV  
- Performance:  
  - Accuracy: **91.03%**  
  - F1-score (Breakout class): **0.61**  
  - Macro F1: **0.78**  
  - ROC AUC: **> 0.90**  

Evaluation visualizations include:
- ROC curve  
- Confusion matrix  
- SHAP summary and importance plots  
- Histogram of predicted breakout probabilities  

# 🔍 Interpretability with SHAP

SHAP values revealed:
- `goal_growth`, `assist_growth`, and `assists` were the **top predictors**  
- Visual plots showed how player features like minutes and appearances contribute to breakout probability  
- SHAP dependence plots gave intuitive, position-specific breakdowns  

# 📦 Download Files

- 🔗 [Top 20 Future Predictions (CSV)](../top_20_future_predicted_breakouts_2526.csv)

# 🧪 Key Code Example

```{python}
import matplotlib.pyplot as plt
import numpy as np

# Confusion matrix example
labels = ['True Negative', 'False Positive', 'False Negative', 'True Positive']
values = [95, 5, 8, 92]

fig, ax = plt.subplots()
bars = ax.bar(labels, values, color=["#4CAF50", "#F44336", "#FF9800", "#2196F3"])
ax.set_title("Confusion Matrix Breakdown")
ax.set_ylabel("Number of Predictions")
plt.xticks(rotation=15)
plt.tight_layout()
plt.show()

# Feature importance example
features = ['goal_growth', 'assist_growth', 'assists', 'minutes_played']
importances = [0.32, 0.24, 0.21, 0.13]

plt.figure(figsize=(6, 4))
plt.barh(features, importances, color="purple")
plt.xlabel("Importance Score")
plt.title("Top Feature Importances (XGBoost)")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()
```

## 🎬 Video Walkthrough

<iframe width="100%" height="400" src="https://www.youtube.com/embed/PxgVFp5a0E4?start=14" title="Data Analysis with Pandas - YouTube" frameborder="0" allowfullscreen></iframe>

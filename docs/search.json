[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "ğŸ“„ Resume",
    "section": "",
    "text": "## ğŸ“„ Resume\nDownload my full CV:\n\n### ğŸ“ Education\nBSc in Computer Science, Springfield University (2020â€“2024)\n### ğŸ’¼ Skills\nPython, JavaScript, SQL, Pandas, NumPy, Plotly, HTML, CSS, GitHub\n### ğŸ§ª Experience\nData Science Intern @ Apex Analytics\n- Built predictive ML models\n- Automated data pipelines with Python\n### ğŸ”¬ Projects\n- Portfolio website with Quarto\n- Breakout prediction model with XGBoost\n### ğŸ“œ Certifications\n- Python for Data Science (Coursera)\n- SQL Foundations (Udemy)"
  },
  {
    "objectID": "projects/project3.html",
    "href": "projects/project3.html",
    "title": "Project 3: Web Scraping and Visualization",
    "section": "",
    "text": "Overview\nIn this project, I scraped data from the web using Python and created visualizations to present insights.\n\n\nSkills Demonstrated\n\nWeb Scraping\nData Cleaning\nData Visualization\n\n\n\nKey Code Example\n\n# Import Libraries\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Scrape sample data\nurl = \"https://example.com\"\nhtml_content = \"&lt;html&gt;&lt;body&gt;&lt;table&gt;&lt;tr&gt;&lt;th&gt;Item&lt;/th&gt;&lt;th&gt;Value&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Apples&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Oranges&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt;\"\nsoup = BeautifulSoup(html_content, \"html.parser\")\n\n# Parse table into DataFrame\ntable = soup.find(\"table\")\nrows = table.find_all(\"tr\")\ndata = []\nfor row in rows[1:]:\n    cols = row.find_all(\"td\")\n    data.append([col.text for col in cols])\n\ndf = pd.DataFrame(data, columns=[\"Item\", \"Value\"])\ndf[\"Value\"] = df[\"Value\"].astype(int)\n\n# Show DataFrame\nprint(df)\n\n# Visualization\nplt.bar(df[\"Item\"], df[\"Value\"], color=[\"green\", \"orange\"])\nplt.title(\"Sample Scraped Data Visualization\")\nplt.xlabel(\"Item\")\nplt.ylabel(\"Value\")\nplt.grid(axis=\"y\")\nplt.show()\n\n      Item  Value\n0   Apples     10\n1  Oranges     15"
  },
  {
    "objectID": "projects/project1.html",
    "href": "projects/project1.html",
    "title": "Project 1: Predicting Breakout Footballers with Machine Learning",
    "section": "",
    "text": "In this project, I built a machine learning pipeline to predict breakout football playersâ€”those expected to drastically improve their goals or assists in the coming season. This was done using real-world player statistics and advanced ML interpretability tools like SHAP.\nThe project used over 10 million data points and statistics from 2013 to April 2025, and was built to support recruitment workflows like those used by clubs such as Brighton or Liverpool."
  },
  {
    "objectID": "projects/project1.html#video-walkthrough",
    "href": "projects/project1.html#video-walkthrough",
    "title": "Project 1: Predicting Breakout Footballers with Machine Learning",
    "section": "ğŸ¬ Video Walkthrough",
    "text": "ğŸ¬ Video Walkthrough"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "ğŸš€ My Featured Projects",
    "section": "",
    "text": "âš½ Predicting Breakout Footballers\n\n\nSkills: Feature Engineering, Classification, SHAP Tools: Python, XGBoost\n\n\nML pipeline that predicts which players will break out in the next season using 10M+ data points and SHAP explainability.\n\nView Project â”\n\n\n\n\n\n\n\nğŸš— Power BI Sales Dashboard\n\n\nSkills: Data Modeling, Dashboarding, DAX Tools: Power BI\n\n\nInteractive report analyzing luxury auto sales by year, region, and product line with KPIs and strategic visuals.\n\nView Project â”\n\n\n\n\n\n\n\nğŸŒ Web Scraping and Visualization\n\n\nSkills: Web Scraping, Data Visualization Tools: Python, BeautifulSoup, Plotly\n\n\nThis project involves scraping website data and creating interactive visualizations.\n\nView Project â”\n\n\n\n\n\n\n\nğŸ—ƒï¸ SQL Integration\n\n\nSkills: SQL Queries, Data Retrieval, Integration Tools: SQLite, Pandas, Jupyter\n\n\nThis project demonstrates integrating SQL queries into Python workflows using real-world data.\n\nView Project â”"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "ğŸ‘‹ About Me",
    "section": "",
    "text": "## ğŸ‘¨â€ğŸ’» About Me\nIâ€™m a Computer Science student with a passion for: - Data Analysis & Machine Learning\n- Full-stack Web Development\n- Problem solving through Python\nIâ€™m currently exploring ways to predict sports outcomes using real-world data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ğŸ‘‹ Welcome",
    "section": "",
    "text": "ğŸ‘‹ Hello, Iâ€™m Conor English\n\n\nWelcome to my personal e-portfolio, built with Quarto! Explore my data science projects, resume, and learning reflections.\n\n\n\nğŸ“ Projects â€“ Real-world Python & Data projects\n\n\nğŸ“„ Resume â€“ Education, skills, and experience\n\n\nğŸ§  Reflection â€“ Learning journey and insights\n\n\n\n\n\nâ€œSuccess is the sum of small efforts repeated day in and day out.â€"
  },
  {
    "objectID": "projects/project-sql.html",
    "href": "projects/project-sql.html",
    "title": "Project: SQL Integration Example",
    "section": "",
    "text": "ğŸ§  Overview\nIn this project, I demonstrate the use of SQL alongside Python using sqlite3 and pandas.\nThis integration allows for efficient data querying and analysis directly from relational databases.\n\n\n\nğŸ” Setup and SQL Queries\nimport sqlite3 import pandas as pd\n\n\nCreate an in-memory SQLite database\nconn = sqlite3.connect(â€œ:memory:â€)\n\n\nCreate table\nconn.execute(â€œâ€œâ€ CREATE TABLE players ( id INTEGER PRIMARY KEY, name TEXT, goals INTEGER, assists INTEGER ); â€œâ€œâ€œ)\n\n\nInsert data\nconn.executemany(â€œINSERT INTO players (name, goals, assists) VALUES (?, ?, ?);â€, [ (â€˜Aliceâ€™, 10, 3), (â€˜Bobâ€™, 7, 5), (â€˜Charlieâ€™, 2, 8)])\n\n\nQuery players with more than 5 goals\ndf = pd.read_sql_query(â€œSELECT * FROM players WHERE goals &gt; 5;â€, conn) df"
  },
  {
    "objectID": "projects/project2.html",
    "href": "projects/project2.html",
    "title": "Project 2: Visualizing Luxury Auto Sales with Power BI",
    "section": "",
    "text": "This project explores the global sales performance of luxury automobiles between 2018 and 2020 using Power BI. It uncovers market trends, product line strengths, and customer behavior patterns. The dashboard is tailored for strategic decision-making in high-end automotive businesses."
  },
  {
    "objectID": "projects/project2.html#sales-per-year",
    "href": "projects/project2.html#sales-per-year",
    "title": "Project 2: Visualizing Luxury Auto Sales with Power BI",
    "section": "ğŸ“… Sales Per Year",
    "text": "ğŸ“… Sales Per Year\n\n\n\nSales Per Year"
  },
  {
    "objectID": "projects/project2.html#sales-per-product-line",
    "href": "projects/project2.html#sales-per-product-line",
    "title": "Project 2: Visualizing Luxury Auto Sales with Power BI",
    "section": "ğŸ·ï¸ Sales Per Product Line",
    "text": "ğŸ·ï¸ Sales Per Product Line\n\n\n\nSales Per Deal Size"
  },
  {
    "objectID": "projects/project2.html#illustrative-code-python-representation",
    "href": "projects/project2.html#illustrative-code-python-representation",
    "title": "Project 2: Visualizing Luxury Auto Sales with Power BI",
    "section": "ğŸ§ª Illustrative Code (Python Representation)",
    "text": "ğŸ§ª Illustrative Code (Python Representation)\n\n\nShow the visuals\nimport matplotlib.pyplot as plt\n\nproduct_lines = ['Classic Cars', 'Vintage Cars', 'Motorcycles', 'Trucks']\nsales_millions = [3.8, 2.4, 1.6, 1.2]\n\nplt.figure(figsize=(6, 4))\nplt.barh(product_lines, sales_millions, color=\"darkblue\")\nplt.xlabel(\"Sales (in millions USD)\")\nplt.title(\"Luxury Auto Sales by Product Line\")\nplt.gca().invert_yaxis()\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "reflection.html",
    "href": "reflection.html",
    "title": "ğŸ§  Reflection",
    "section": "",
    "text": "## ğŸ§  Reflection\nThis portfolio journey helped me:\n\nApply data science principles to real projects\nLearn Git/GitHub version control deeply\nGain web publishing experience with Quarto\n\n### ğŸ’¡ Key Lessons - Importance of visual design in communicating work - Iteration and polish matter more than perfection - Small bugs are part of the learning process!"
  }
]